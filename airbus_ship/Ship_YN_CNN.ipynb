{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"data/airbus_ship/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>231723</td>\n",
       "      <td>81723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>192556</td>\n",
       "      <td>81722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e2615fb70.jpg</td>\n",
       "      <td>43801 1 44567 4 45334 5 46100 8 46867 9 47636 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId                                      EncodedPixels\n",
       "count          231723                                              81723\n",
       "unique         192556                                              81722\n",
       "top     e2615fb70.jpg  43801 1 44567 4 45334 5 46100 8 46867 9 47636 ...\n",
       "freq               15                                                  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_df = pd.read_csv(f\"{PATH}train_ship_segmentations_v2.csv\")\n",
    "masks_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>81723</td>\n",
       "      <td>81723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>42556</td>\n",
       "      <td>81722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e2615fb70.jpg</td>\n",
       "      <td>43801 1 44567 4 45334 5 46100 8 46867 9 47636 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId                                      EncodedPixels\n",
       "count           81723                                              81723\n",
       "unique          42556                                              81722\n",
       "top     e2615fb70.jpg  43801 1 44567 4 45334 5 46100 8 46867 9 47636 ...\n",
       "freq               15                                                  2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_df_nona = masks_df.dropna()\n",
    "masks_df_nona.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new column: ShipPres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtolstokory/anaconda3/envs/42/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShipPres</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000155de5.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000194a2d.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00021ddc3.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002756f7.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00031f145.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ShipPres\n",
       "ImageId                \n",
       "000155de5.jpg         1\n",
       "000194a2d.jpg         1\n",
       "00021ddc3.jpg         1\n",
       "0002756f7.jpg         1\n",
       "00031f145.jpg         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_df[\"ShipPres\"] = masks_df[\"EncodedPixels\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "all_yn = masks_df.groupby([\"ImageId\"])[\"ShipPres\"].agg({\"ShipPres\": \"max\"})\n",
    "ship_pres = all_yn[all_yn[\"ShipPres\"] == 1]\n",
    "noship_pres = all_yn[all_yn[\"ShipPres\"] == 0]\n",
    "TOTAL_WSHIPS = len(ship_pres)\n",
    "ship_pres.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glue together NUM_SAMPLES images with ships and without ships for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ShipPres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18af9a74d.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c85965f88.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3447c0ffc.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86195f10d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e5f7cddc.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>275c98805.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26d81d437.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d36988638.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d42a50c68.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8872cdf6c.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  ShipPres\n",
       "0  18af9a74d.jpg         0\n",
       "1  c85965f88.jpg         1\n",
       "2  3447c0ffc.jpg         1\n",
       "3  86195f10d.jpg         1\n",
       "4  1e5f7cddc.jpg         1\n",
       "5  275c98805.jpg         1\n",
       "6  26d81d437.jpg         1\n",
       "7  d36988638.jpg         0\n",
       "8  d42a50c68.jpg         0\n",
       "9  8872cdf6c.jpg         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_SAMPLES = 1000\n",
    "train_df = pd.concat([ship_pres.sample(NUM_SAMPLES),noship_pres.sample(NUM_SAMPLES)])\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
    "train_df = train_df.reset_index()\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important for monitoring metrics in tensorboard\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataframe to get validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ShipPres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>bd0004835.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>888b9510f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>8979482c3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>37db2f40f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>2d781d734.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ImageId  ShipPres\n",
       "1400  bd0004835.jpg         1\n",
       "1401  888b9510f.jpg         0\n",
       "1402  8979482c3.jpg         0\n",
       "1403  37db2f40f.jpg         0\n",
       "1404  2d781d734.jpg         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPLIT = int((NUM_SAMPLES*2/100.0)*70)\n",
    "valid_df = train_df.loc[SPLIT:]\n",
    "train_df = train_df.loc[:SPLIT]\n",
    "valid_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_input_fn(files,labels, batch_size, num_epochs=1,shuffle=True):\n",
    "    \n",
    "    def _input_fn():\n",
    "        # step 1\n",
    "        #files = files.apply(lambda x: path + x)\n",
    "        filenames = tf.constant(list(files))\n",
    "        _labels = tf.constant(list(labels))\n",
    "\n",
    "        # step 2: create a dataset returning slices of `filenames`\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filenames, _labels))\n",
    "\n",
    "        # step 3: parse every image in the dataset using `map`\n",
    "        def _parse_function(filename, label):\n",
    "            image_string = tf.read_file(filename)#tf.strings.join([path,filename])\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3,try_recover_truncated=True)\n",
    "            image = tf.cast(image_decoded, tf.float32)\n",
    "            return image, label\n",
    "\n",
    "        dataset = dataset.map(_parse_function)\n",
    "        dataset = dataset.batch(batch_size).repeat(num_epochs)\n",
    "\n",
    "        if shuffle:\n",
    "          dataset = dataset.shuffle(100)\n",
    "        \n",
    "        # step 4: create iterator and final input tensor\n",
    "        image_batch, label_batch = dataset.make_one_shot_iterator().get_next()\n",
    "        \n",
    "        #tf.Print(label_batch,[label_batch],message=\"Image: \")\n",
    "        \n",
    "        return image_batch, label_batch\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_input_fn(files, labels, batch_size):\n",
    "    \n",
    "    def _input_fn():\n",
    "        # step 1\n",
    "        filenames = tf.constant(list(files))\n",
    "        _labels = tf.constant(list(labels))\n",
    "\n",
    "        # step 2: create a dataset returning slices of `filenames`\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filenames, _labels))\n",
    "\n",
    "        # step 3: parse every image in the dataset using `map`\n",
    "        def _parse_function(filename, label):\n",
    "            image_string = tf.read_file(filename)#tf.strings.join([path,filename])\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3,try_recover_truncated=True)\n",
    "            image = tf.cast(image_decoded, tf.float32)\n",
    "            return image, label\n",
    "\n",
    "        dataset = dataset.map(_parse_function)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        \n",
    "        # step 4: create iterator and final input tensor\n",
    "        image_batch, label_batch = dataset.make_one_shot_iterator().get_next()\n",
    "        \n",
    "        return image_batch, label_batch\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = create_train_input_fn(train_df[\"ImageId\"].apply(lambda x: f\"{PATH}train/\" + x),train_df[\"ShipPres\"],\n",
    "                                       batch_size=BATCH_SIZE)\n",
    "valid_input_fn = create_predict_input_fn(valid_df[\"ImageId\"].apply(lambda x: f\"{PATH}train/\" + x),valid_df[\"ShipPres\"],\n",
    "                                       batch_size=BATCH_SIZE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hooks = [tf_debug.LocalCLIDebugHook()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sess = tf.InteractiveSession()\n",
    "img_b, label_b = train_input_fn()\n",
    "print_out = tf.Print(img_b,[img_b],message=\"Image: \")\n",
    "print_out.eval()\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(features, labels, mode):\n",
    "    XX = tf.reshape(features, [-1,768,768,3])\n",
    "    Y1 = tf.layers.conv2d(XX, filters=6, kernel_size=[6,6], padding='same', activation=tf.nn.leaky_relu)\n",
    "    Y2 = tf.layers.conv2d(Y1, filters=12, kernel_size=[5,5], strides=(2,2), padding='same', activation=tf.nn.leaky_relu)\n",
    "    Y3 = tf.layers.conv2d(Y2, filters=24, kernel_size=[4,4], strides=(2,2), padding='same', activation=tf.nn.leaky_relu)\n",
    "    Y4 = tf.layers.flatten(Y3)\n",
    "    Y5 = tf.layers.dense(Y4, units = 200, activation=tf.nn.leaky_relu)\n",
    "    Y6 = tf.layers.dropout(Y5, rate = 0.1, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    logits = tf.layers.dense(Y6,units = 2)\n",
    "\n",
    "    predictions = {\n",
    "                    \"classes\": tf.argmax(input=logits, axis=1),\n",
    "                    \"probabilities\": tf.nn.softmax(logits)\n",
    "    }\n",
    "    \n",
    "    #define predict method logic\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, predictions=predictions)\n",
    "    \n",
    "    #sparse_softmax does one-hot automatically\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)\n",
    "    accuracy = tf.metrics.accuracy(labels = labels, predictions = predictions[\"classes\"], name = \"acc_op\")\n",
    "    \n",
    "    \n",
    "    #define train method logic\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op  = optimizer.minimize(\n",
    "            loss = loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        tf.identity(accuracy[1], name='train_accuracy')\n",
    "        tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "        eval_metric_ops = {\"train_accuracy\":accuracy}\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_op, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #define evaluate method logic\n",
    "    tf.identity(accuracy[1], name='val_accuracy')\n",
    "    tf.summary.scalar('val_accuracy', accuracy[1])\n",
    "    eval_metric_ops = {\"val_accuracy\":accuracy}\n",
    "    return tf.estimator.EstimatorSpec(mode = mode, loss = loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tf_files\n",
    "OUT_DIR = \"./tf_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './tf_files', '_tf_random_seed': None, '_save_summary_steps': 2, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f27abee8358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.7654436, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 44 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 24.636627.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-20:21:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-44\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-20:21:40\n",
      "INFO:tensorflow:Saving dict for global step 44: global_step = 44, loss = 23.090893, val_accuracy = 0.5133333\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44: ./tf_files/model.ckpt-44\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-44\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 44 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:loss = 23.75143, step = 44\n",
      "INFO:tensorflow:Saving checkpoints for 88 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.257298.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-20:23:10\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-88\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-20:23:22\n",
      "INFO:tensorflow:Saving dict for global step 88: global_step = 88, loss = 5.584546, val_accuracy = 0.60333335\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 88: ./tf_files/model.ckpt-88\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-88\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 88 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.3438673, step = 88\n",
      "INFO:tensorflow:Saving checkpoints for 132 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.3827095.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-20:24:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-132\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-20:25:00\n",
      "INFO:tensorflow:Saving dict for global step 132: global_step = 132, loss = 5.885016, val_accuracy = 0.60333335\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 132: ./tf_files/model.ckpt-132\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-132\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 132 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.9348783, step = 132\n",
      "INFO:tensorflow:Saving checkpoints for 176 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.138043.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-20:26:16\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-176\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-20:26:28\n",
      "INFO:tensorflow:Saving dict for global step 176: global_step = 176, loss = 8.637631, val_accuracy = 0.57166666\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 176: ./tf_files/model.ckpt-176\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-176\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 176 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.4705675, step = 176\n",
      "INFO:tensorflow:Saving checkpoints for 220 into ./tf_files/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4212351.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-08-20:27:46\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_files/model.ckpt-220\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-08-20:27:58\n",
      "INFO:tensorflow:Saving dict for global step 220: global_step = 220, loss = 3.2526093, val_accuracy = 0.6\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 220: ./tf_files/model.ckpt-220\n"
     ]
    }
   ],
   "source": [
    "my_cnn_classifier = tf.estimator.Estimator(model_fn=conv_model, \n",
    "                                           config=tf.estimator.RunConfig(keep_checkpoint_max=1).replace(save_summary_steps=2),\n",
    "                                           model_dir=OUT_DIR)\n",
    "file_writer = tf.summary.FileWriter(OUT_DIR)\n",
    "\n",
    "def train_and_eval(estimator, num_epochs = NUM_EPOCHS, steps=100):\n",
    "    for n in range(num_epochs):\n",
    "        estimator.train(input_fn = train_input_fn,steps = steps)\n",
    "        estimator.evaluate(input_fn = valid_input_fn)\n",
    "        \n",
    "train_and_eval(my_cnn_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission file generation(will be implemented in full version):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generator = my_cnn_classifier.predict(input_fn=test_input_fn)\n",
    "predictions = [next(generator) for i in range(len(test_images))]\n",
    "classes = [predictions[i][\"classes\"] for i in range(len(predictions))]\n",
    "\n",
    "def make_submission_file(classes, filename):\n",
    "    submission = pd.DataFrame()\n",
    "    submission[\"ImageId\"] = range(1, 28001)\n",
    "    submission[\"Label\"] = classes\n",
    "    submission.set_index(\"ImageId\", inplace=True)\n",
    "    submission.to_csv(filename)\n",
    "    \n",
    "make_submission_file(classes, \"shippres.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
